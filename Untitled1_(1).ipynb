{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neha202801/Dendrite.AI/blob/main/Untitled1_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4cdcbe",
      "metadata": {
        "id": "7b4cdcbe",
        "outputId": "acea5389-998f-48c7-d68c-a23f6f196b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Type: Regression\n",
            "Target Variable: petal_width\n",
            "Regression Type: regression\n",
            "Partitioning Enabled: True\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def parse_target_config(json_data):\n",
        "    # Extracting the 'target' section from the JSON\n",
        "    target_config = json_data.get(\"target\", {})\n",
        "\n",
        "    # Reading the required information\n",
        "    prediction_type = target_config.get(\"prediction_type\", \"Not specified\")\n",
        "    target_variable = target_config.get(\"target\", \"Not specified\")\n",
        "    regression_type = target_config.get(\"type\", \"Not specified\")\n",
        "    partitioning = target_config.get(\"partitioning\", False)\n",
        "\n",
        "    # Printing the extracted information\n",
        "    print(f\"Prediction Type: {prediction_type}\")\n",
        "    print(f\"Target Variable: {target_variable}\")\n",
        "    print(f\"Regression Type: {regression_type}\")\n",
        "    print(f\"Partitioning Enabled: {partitioning}\")\n",
        "\n",
        "# Example JSON input\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"target\": {\n",
        "    \"prediction_type\": \"Regression\",\n",
        "    \"target\": \"petal_width\",\n",
        "    \"type\": \"regression\",\n",
        "    \"partitioning\": true\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the provided JSON\n",
        "json_data = json.loads(json_input)\n",
        "parse_target_config(json_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9362fb8",
      "metadata": {
        "id": "e9362fb8",
        "outputId": "12b86440-a60f-4951-95e9-20b352cbb4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Your JSON input as a string\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"feature_handling\": {\n",
        "    \"sepal_length\": {\n",
        "      \"feature_name\": \"sepal_length\",\n",
        "      \"is_selected\": true,\n",
        "      \"feature_variable_type\": \"numerical\",\n",
        "      \"feature_details\": {\n",
        "        \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "        \"rescaling\": \"No rescaling\",\n",
        "        \"make_derived_feats\": false,\n",
        "        \"missing_values\": \"Impute\",\n",
        "        \"impute_with\": \"Average of values\",\n",
        "        \"impute_value\": 0\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the JSON input to get the configuration\n",
        "feature_config = json.loads(json_input)\n",
        "\n",
        "# Function to apply imputation based on the feature configuration\n",
        "def apply_imputation(df, feature_config):\n",
        "    for feature, config in feature_config[\"feature_handling\"].items():\n",
        "        if config[\"feature_details\"][\"missing_values\"] == \"Impute\":\n",
        "            if config[\"feature_details\"][\"impute_with\"] == \"Average of values\":\n",
        "                # Calculate the average without considering NaN values\n",
        "                avg_value = df[feature].mean()\n",
        "                # Fill NaN values with the calculated average\n",
        "                df[feature].fillna(avg_value, inplace=True)\n",
        "            # Extend this block to handle other imputation methods as needed\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\INDIA\\Downloads\\\\DS_Assignment - internship (1)\\\\Screening Test - DS\\\\iris.csv\")\n",
        "\n",
        "# Apply the imputation to the DataFrame based on the configuration\n",
        "apply_imputation(df, feature_config)\n",
        "\n",
        "# Display the DataFrame to verify the imputation\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11575849",
      "metadata": {
        "id": "11575849",
        "outputId": "4e029a35-aed9-4249-a484-162733b17e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming df is your DataFrame and target_variable is your target column's name\n",
        "def apply_feature_reduction(df, target_variable, config):\n",
        "    method = config[\"feature_reduction_method\"]\n",
        "    reduced_df = df.copy()\n",
        "\n",
        "    # No Reduction\n",
        "    if config[\"No Reduction\"][\"is_selected\"]:\n",
        "        # Assuming 'No Reduction' simply means limiting the number of features without any specific method\n",
        "        num_features = config[\"No Reduction\"][\"num_of_features_to_keep\"]\n",
        "        reduced_df = reduced_df.iloc[:, :num_features]\n",
        "\n",
        "    # Correlation with Target\n",
        "    elif config[\"Correlation with target\"][\"is_selected\"]:\n",
        "        num_features = config[\"Correlation with target\"][\"num_of_features_to_keep\"]\n",
        "        corr_scores = {col: pearsonr(df[col], df[target_variable])[0] for col in df.columns if df[col].dtype != 'object' and col != target_variable}\n",
        "        sorted_features = sorted(corr_scores, key=corr_scores.get, reverse=True)[:num_features]\n",
        "        reduced_df = df[sorted_features + [target_variable]]\n",
        "\n",
        "    # Tree-based\n",
        "    elif config[\"Tree-based\"][\"is_selected\"]:\n",
        "        num_features = config[\"Tree-based\"][\"num_of_features_to_keep\"]\n",
        "        clf = ExtraTreesClassifier(n_estimators=config[\"Tree-based\"][\"num_of_trees\"])\n",
        "        clf = clf.fit(df.drop(target_variable, axis=1), df[target_variable])\n",
        "        importances = clf.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1][:num_features]\n",
        "        selected_features = df.columns[indices]\n",
        "        reduced_df = df[selected_features.tolist() + [target_variable]]\n",
        "\n",
        "    # PCA\n",
        "    elif config[\"Principal Component Analysis\"][\"is_selected\"]:\n",
        "        num_features = config[\"Principal Component Analysis\"][\"num_of_features_to_keep\"]\n",
        "        pca = PCA(n_components=num_features)\n",
        "        principalComponents = pca.fit_transform(df.drop(target_variable, axis=1))\n",
        "        reduced_df = pd.DataFrame(data = principalComponents, columns = [f'PC{i}' for i in range(1, num_features + 1)])\n",
        "        reduced_df[target_variable] = df[target_variable]\n",
        "\n",
        "    return reduced_df\n",
        "\n",
        "# Example usage:\n",
        "json_config = {\n",
        "  \"feature_reduction_method\": \"Correlation with target\",\n",
        "  \"No Reduction\": {\"is_selected\": True, \"num_of_features_to_keep\": 5},\n",
        "  \"Correlation with target\": {\"is_selected\": False, \"num_of_features_to_keep\": 8},\n",
        "  \"Tree-based\": {\"is_selected\": False, \"num_of_features_to_keep\": 0, \"depth_of_trees\": 0, \"num_of_trees\": 0},\n",
        "  \"Principal Component Analysis\": {\"is_selected\": False, \"num_of_features_to_keep\": 0},\n",
        "}\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\INDIA\\\\Downloads\\\\DS_Assignment - internship (1)\\\\Screening Test - DS\\\\iris.csv\")\n",
        "target_variable = 'YourTargetColumnNameHere'\n",
        "\n",
        "# Apply feature reduction\n",
        "reduced_df = apply_feature_reduction(df, target_variable, json_config)\n",
        "\n",
        "# Check the result\n",
        "print(reduced_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064df202",
      "metadata": {
        "id": "064df202",
        "outputId": "f28653cc-9224-489c-f4ea-15e5fb6223fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.5384615384615383, max_iter=40)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Sample JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "  \"prediction_type\": \"Classification\",\n",
        "  \"models\": {\n",
        "    \"LogisticRegression\": {\n",
        "      \"model_name\": \"LogisticRegression\",\n",
        "      \"is_selected\": true,\n",
        "      \"parallelism\": 2,\n",
        "      \"min_iter\": 30,\n",
        "      \"max_iter\": 50,\n",
        "      \"min_regparam\": 0.5,\n",
        "      \"max_regparam\": 0.8,\n",
        "      \"min_elasticnet\": 0.5,\n",
        "      \"max_elasticnet\": 0.8\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Function to parse JSON and instantiate models\n",
        "def instantiate_model_from_json(json_str):\n",
        "    config = json.loads(json_str)\n",
        "    models = []\n",
        "\n",
        "    if config[\"prediction_type\"] == \"Classification\":\n",
        "        # For each model configuration\n",
        "        for model_name, model_config in config[\"models\"].items():\n",
        "            if model_config[\"is_selected\"]:\n",
        "                if model_name == \"LogisticRegression\":\n",
        "                    # Example: Instantiate logistic regression with averaged parameters\n",
        "                    # Adjust the instantiation as needed based on the parameters you want to use\n",
        "                    lr = LogisticRegression(\n",
        "                        max_iter=int((model_config[\"min_iter\"] + model_config[\"max_iter\"]) / 2),\n",
        "                        C=1.0 / ((model_config[\"min_regparam\"] + model_config[\"max_regparam\"]) / 2),  # Inverse of regularization strength\n",
        "                        # L1 ratio or other parameters related to elastic net can be set similarly\n",
        "                    )\n",
        "                    models.append(lr)\n",
        "                # Extend with elif blocks for other classification models as needed\n",
        "    elif config[\"prediction_type\"] == \"Regression\":\n",
        "        # Instantiate regression models similarly, for example:\n",
        "        pass  # Add logic for regression models here\n",
        "\n",
        "    return models\n",
        "\n",
        "# Example usage\n",
        "models = instantiate_model_from_json(json_config)\n",
        "for model in models:\n",
        "    print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1077bbe6",
      "metadata": {
        "id": "1077bbe6",
        "outputId": "a5c7a097-27c2-4cad-953e-7c2b026d57d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for RandomForest: {'max_depth': 20, 'n_estimators': 50}\n",
            "Best score for RandomForest: -0.1992035554536368\n",
            "Predictions for RandomForest: [0.55530078 0.48577911 0.32028595 0.4161539  0.34398312 0.51684688\n",
            " 0.49255198 0.56056987 0.52962936 0.62845466 0.49111118 0.45967094\n",
            " 0.69783327 0.6012238  0.47771374 0.41398884 0.4843337  0.58082719\n",
            " 0.48571466 0.64505418 0.45245063 0.52836399 0.41515258 0.39737676\n",
            " 0.52096648 0.40566903 0.39720763 0.60874526 0.52617221 0.57835099\n",
            " 0.59356283 0.57495966 0.36647006 0.5071669  0.68789611 0.63726956\n",
            " 0.4537241  0.51257257 0.54100206 0.34065648 0.49371113 0.36851373\n",
            " 0.65249889 0.55708446 0.42336145 0.70590096 0.55962662 0.44362689\n",
            " 0.65422916 0.4730897 ]\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.14294183490150064\n",
            "Predictions for SVR: [0.54344206 0.493975   0.46608577 0.49338543 0.39010518 0.46288105\n",
            " 0.49395102 0.51495928 0.50660974 0.65401805 0.41084747 0.33763416\n",
            " 0.60870877 0.43666034 0.43426949 0.47124133 0.5470962  0.48717917\n",
            " 0.47852569 0.59937472 0.5633899  0.47955283 0.39477014 0.32085902\n",
            " 0.5473031  0.3726701  0.40437926 0.53555319 0.55948057 0.56641789\n",
            " 0.53730805 0.57587647 0.49912358 0.47448012 0.61756242 0.5497174\n",
            " 0.53851222 0.63799555 0.58529677 0.45708664 0.50840475 0.48166607\n",
            " 0.58030277 0.49642153 0.40739139 0.57353085 0.46382043 0.42789391\n",
            " 0.53877246 0.40859531]\n",
            "Best parameters for LinearRegression: {'fit_intercept': False}\n",
            "Best score for LinearRegression: -0.5244385382817255\n",
            "Predictions for LinearRegression: [0.66537853 0.51851792 0.39807566 0.58165887 0.48321414 0.47321857\n",
            " 0.48910026 0.62858351 0.60723647 0.67714914 0.37145992 0.16761147\n",
            " 0.62123398 0.40547305 0.36532922 0.4028506  0.51024425 0.26096983\n",
            " 0.45626663 0.69989089 0.72631198 0.5764041  0.3611896  0.43014771\n",
            " 0.48400462 0.24281781 0.26913154 0.67884566 0.66738619 0.70349681\n",
            " 0.58053246 0.76494145 0.4269825  0.34450043 0.75384501 0.36513559\n",
            " 0.595687   0.75039342 0.74227521 0.58808883 0.59073286 0.46150675\n",
            " 0.52780468 0.50192399 0.4392723  0.62699876 0.36639955 0.27752734\n",
            " 0.6611195  0.33946469]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X_train = np.random.rand(100, 10)\n",
        "y_train = np.random.rand(100)\n",
        "X_test = np.random.rand(50, 10)\n",
        "y_test=np.random.rand(50)\n",
        "\n",
        "# Define models and their parameter grids\n",
        "models = {\n",
        "    \"RandomForest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}),\n",
        "    \"SVR\": (SVR(), {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10]}),\n",
        "    \"LinearRegression\": (LinearRegression(), {'fit_intercept': [True, False]})\n",
        "}\n",
        "\n",
        "# TimeSeriesSplit cross-validation with overlap\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee8319d",
      "metadata": {
        "id": "3ee8319d",
        "outputId": "cc48ad4e-5957-43b9-ddce-b9952b304dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for RandomForest: {'max_depth': 20, 'n_estimators': 100}\n",
            "Best score for RandomForest: -0.20668821612278981\n",
            "Predictions for RandomForest: [0.63335323 0.4435915  0.37735551 0.46747934 0.3182195  0.55946303\n",
            " 0.57001081 0.54673871 0.58168374 0.61781011 0.45405637 0.40166228\n",
            " 0.51816421 0.59333227 0.39203984 0.47288381 0.47271452 0.6162819\n",
            " 0.44196974 0.60018656 0.39662813 0.57252989 0.36726935 0.33114506\n",
            " 0.51680857 0.45752309 0.38120064 0.61768201 0.482679   0.60875256\n",
            " 0.49346131 0.62390079 0.35817369 0.44326067 0.6872614  0.61437275\n",
            " 0.40214167 0.48840898 0.5895022  0.32442184 0.4219283  0.31376113\n",
            " 0.59289796 0.47029837 0.4567013  0.73347981 0.49222947 0.46358073\n",
            " 0.62695361 0.41890152]\n",
            "Mean Absolute Error for RandomForest: 0.2766886821305882\n",
            "Mean Squared Error for RandomForest: 0.0990522419535322\n",
            "R-squared for RandomForest: -0.040207029488999346\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.14294183490150064\n",
            "Predictions for SVR: [0.54344206 0.493975   0.46608577 0.49338543 0.39010518 0.46288105\n",
            " 0.49395102 0.51495928 0.50660974 0.65401805 0.41084747 0.33763416\n",
            " 0.60870877 0.43666034 0.43426949 0.47124133 0.5470962  0.48717917\n",
            " 0.47852569 0.59937472 0.5633899  0.47955283 0.39477014 0.32085902\n",
            " 0.5473031  0.3726701  0.40437926 0.53555319 0.55948057 0.56641789\n",
            " 0.53730805 0.57587647 0.49912358 0.47448012 0.61756242 0.5497174\n",
            " 0.53851222 0.63799555 0.58529677 0.45708664 0.50840475 0.48166607\n",
            " 0.58030277 0.49642153 0.40739139 0.57353085 0.46382043 0.42789391\n",
            " 0.53877246 0.40859531]\n",
            "Mean Absolute Error for SVR: 0.27078388642446327\n",
            "Mean Squared Error for SVR: 0.09945753868261129\n",
            "R-squared for SVR: -0.04446329364114976\n",
            "Best parameters for LinearRegression: {'fit_intercept': False}\n",
            "Best score for LinearRegression: -0.5244385382817255\n",
            "Predictions for LinearRegression: [0.66537853 0.51851792 0.39807566 0.58165887 0.48321414 0.47321857\n",
            " 0.48910026 0.62858351 0.60723647 0.67714914 0.37145992 0.16761147\n",
            " 0.62123398 0.40547305 0.36532922 0.4028506  0.51024425 0.26096983\n",
            " 0.45626663 0.69989089 0.72631198 0.5764041  0.3611896  0.43014771\n",
            " 0.48400462 0.24281781 0.26913154 0.67884566 0.66738619 0.70349681\n",
            " 0.58053246 0.76494145 0.4269825  0.34450043 0.75384501 0.36513559\n",
            " 0.595687   0.75039342 0.74227521 0.58808883 0.59073286 0.46150675\n",
            " 0.52780468 0.50192399 0.4392723  0.62699876 0.36639955 0.27752734\n",
            " 0.6611195  0.33946469]\n",
            "Mean Absolute Error for LinearRegression: 0.28070910525434123\n",
            "Mean Squared Error for LinearRegression: 0.11226180012113669\n",
            "R-squared for LinearRegression: -0.1789285262606939\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n",
        "\n",
        "    # Evaluate model performance\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    print(f\"Mean Absolute Error for {name}: {mae}\")\n",
        "    print(f\"Mean Squared Error for {name}: {mse}\")\n",
        "    print(f\"R-squared for {name}: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "555a05bf",
      "metadata": {
        "id": "555a05bf",
        "outputId": "f7873e0d-04fb-4fbd-f261-f563206a6191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed JSON config: {'Grid Search': {'is selected': True, 'RandomForest': {'is_selected': True, 'param_grid': {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}, 'cv': 5}}}\n",
            "No algorithm selected for execution.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "    print(\"Parsed JSON config:\", config)\n",
        "\n",
        "    # Check if Grid Search is selected and an algorithm is specified\n",
        "    if config.get(\"Grid Search\", {}).get(\"is_selected\", False):\n",
        "        algorithm = next((algo for algo in config if algo != \"Grid Search\" and config[algo].get(\"is_selected\", False)), None)\n",
        "        if algorithm:\n",
        "            print(f\"Algorithm '{algorithm}' is selected.\")\n",
        "            return algorithm, config[algorithm]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [null, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260349cd",
      "metadata": {
        "id": "260349cd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}